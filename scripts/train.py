#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ZX-Tokenizer ç®€åŒ–è®­ç»ƒè„šæœ¬
ä¸¥æ ¼æŒ‰ç…§DeepSpeedè§„èŒƒï¼Œé›†æˆæ¨¡å‹é€‰æ‹©ã€æ—©åœå’Œæµ‹è¯•é›†è¯„ä¼°
"""

import os
import sys
import yaml
import argparse
import torch.distributed as dist
import deepspeed
from pathlib import Path
import gc

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°æ¨¡å—è·¯å¾„
project_root = str(Path(__file__).parent.parent)
sys.path.insert(0, project_root)

from audiocodec.trainer.trainer import AudioCodecTrainer
from audiocodec.model import AudioCodec
from utils.helpers import set_logging
from utils.weight_init import load_whisper_weights

def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description="ZX-Tokenizer Training")
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument('--config', '-c', type=str, required=True,
                        help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--stage', type=str, choices=['pretrain', 'posttrain'], 
                        default='pretrain', help='è®­ç»ƒé˜¶æ®µ')

    # æ¢å¤è®­ç»ƒ
    parser.add_argument('--resume', type=str, default=None,
                        help='æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„')              

    # è®©è„šæœ¬æ¥å— DeepSpeed/torch å¯åŠ¨å™¨æ³¨å…¥çš„ local_rank å‚æ•°
    parser.add_argument('--local_rank', type=int, default=int(os.environ.get('LOCAL_RANK', 0)),
                        help='ç”±åˆ†å¸ƒå¼å¯åŠ¨å™¨ä¼ å…¥çš„æœ¬åœ°è¿›ç¨‹åºå·')

    # DeepSpeedä¼šè‡ªåŠ¨æ·»åŠ è¿™äº›å‚æ•°
    parser = deepspeed.add_config_arguments(parser)
    
    return parser.parse_args()


def setup_distributed():
    """è®¾ç½®åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒ"""
    if 'RANK' in os.environ and 'WORLD_SIZE' in os.environ:
        rank = int(os.environ['RANK'])
        world_size = int(os.environ['WORLD_SIZE'])
        local_rank = int(os.environ['LOCAL_RANK'])
    else:
        rank = 0
        world_size = 1
        local_rank = 0
        os.environ['RANK'] = '0'
        os.environ['WORLD_SIZE'] = '1'
        os.environ['LOCAL_RANK'] = '0'
        
    return rank, world_size, local_rank


def load_configuration(config_path: str, args) -> dict:
    """åŠ è½½å¹¶æ›´æ–°é…ç½®"""
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # åˆ›å»ºç›®å½•
    os.makedirs(config['checkpoint_dir'], exist_ok=True)
    os.makedirs(config['log_dir'], exist_ok=True)
    
    return config

def main():
    args = parse_args()
    rank, world_size, local_rank = setup_distributed()
    set_logging("INFO" if rank == 0 else "WARNING")
    config = load_configuration(args.config, args)

    if rank == 0:
        print(f"ğŸš€ å¯åŠ¨AudioCodecè®­ç»ƒ - {args.stage}é˜¶æ®µ")

    # ========================== æ ¸å¿ƒé€»è¾‘æœ€ç»ˆç‰ˆ ==========================
    # 1. åˆ›å»ºæ¨¡å‹
    should_initialize_whisper = (args.stage == 'pretrain' and not args.resume)
    model = AudioCodec(config['model'], initialize_whisper=should_initialize_whisper)

    # 2. å¤„ç†æƒé‡åŠ è½½
    if not args.resume and args.stage == "posttrain":
        pretrained_root = config.get('training', {}).get('pretrained_checkpoint', None)
        if pretrained_root:
            if rank == 0:
                print(f"ğŸ”· ä»å¤´å¼€å§‹åè®­ç»ƒï¼ŒåŠ è½½é¢„è®­ç»ƒ Codec æƒé‡ä» {pretrained_root}...")
            AudioCodecTrainer.load_model_weights(model, pretrained_root)
        elif rank == 0:
            print("âš ï¸ æœªæä¾›é¢„è®­ç»ƒ Codec æƒé‡ï¼Œåè®­ç»ƒå°†ä»éšæœºåˆå§‹åŒ–å¼€å§‹ï¼")

    # 3. åˆ›å»º Trainer
    trainer = AudioCodecTrainer(
        config=config,
        training_stage=args.stage,
        args=args,
        model=model,
        resume_from=args.resume
    )

    # åŒæ­¥æ‰€æœ‰è¿›ç¨‹
    if world_size > 1:
        dist.barrier()

    # 4. å¼€å§‹è®­ç»ƒ
    try:
        trainer.train()
    except KeyboardInterrupt:
        if rank == 0:
            print("è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        if rank == 0:
            print(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        raise
    finally:
        if rank == 0:
            print("è®­ç»ƒç»“æŸ!")

        # 5. æ˜¾å¼åˆ é™¤ trainer å¯¹è±¡
        if rank == 0:
            print("æ­£åœ¨é‡Šæ”¾ Trainer èµ„æº...")
        del trainer
        gc.collect() # å»ºè®®è¿›è¡Œåƒåœ¾å›æ”¶

        # 6. åŒæ­¥å¹¶å®‰å…¨åœ°å…³é—­åˆ†å¸ƒå¼ç¯å¢ƒ
        if world_size > 1:
            dist.barrier()
            
        if rank == 0:
            print("è®­ç»ƒæµç¨‹ç»“æŸï¼Œæ­£åœ¨æ¸…ç†åˆ†å¸ƒå¼ç¯å¢ƒ...")
            
        if world_size > 1 and dist.is_initialized():
            dist.destroy_process_group()
        
        if rank == 0:
            print("ç¨‹åºæ­£å¸¸é€€å‡ºã€‚")


if __name__ == "__main__":
    main()