#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
WERè®¡ç®—è„šæœ¬

åŠŸèƒ½ï¼š
- ä½¿ç”¨HuBERTæ¨¡å‹è½¬å½•é‡å»ºéŸ³é¢‘
- ä¸LibriSpeech test-cleançš„å‚è€ƒè½¬å½•æ–‡æœ¬è®¡ç®—WER
- æ”¯æŒæ‰¹é‡å¤„ç†æ‰€æœ‰ç”Ÿæˆçš„é‡å»ºéŸ³é¢‘
"""

import os
import sys
import json
import argparse
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from tqdm import tqdm
import numpy as np

import torch
import torchaudio
from transformers import Wav2Vec2Processor, HubertForCTC
import jiwer

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('wer_calculation.log', mode='w')
    ]
)
logger = logging.getLogger(__name__)


class WERCalculator:
    """WERè®¡ç®—å™¨"""

    def __init__(self, hubert_model_path: str, device: str = "auto"):
        """
        åˆå§‹åŒ–WERè®¡ç®—å™¨

        Args:
            hubert_model_path: HuBERTæ¨¡å‹è·¯å¾„
            device: è®¡ç®—è®¾å¤‡
        """
        self.device = self._setup_device(device)
        self.hubert_model_path = hubert_model_path
        
        # åŠ è½½HuBERTæ¨¡å‹å’Œå¤„ç†å™¨
        self._load_hubert_model()
        
        logger.info("âœ… WERè®¡ç®—å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"  ğŸ¤– HuBERTæ¨¡å‹: {hubert_model_path}")
        logger.info(f"  ğŸ’» è®¾å¤‡: {self.device}")

    def _setup_device(self, device: str) -> torch.device:
        """è®¾ç½®è®¡ç®—è®¾å¤‡"""
        if device == "auto":
            if torch.cuda.is_available():
                return torch.device('cuda:0')
            else:
                return torch.device('cpu')
        else:
            return torch.device(device)

    def _load_hubert_model(self):
        """åŠ è½½HuBERTæ¨¡å‹"""
        try:
            logger.info("ğŸ”„ æ­£åœ¨åŠ è½½HuBERTæ¨¡å‹...")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ¬åœ°è·¯å¾„
            if os.path.exists(self.hubert_model_path):
                # ä»æœ¬åœ°è·¯å¾„åŠ è½½
                self.processor = Wav2Vec2Processor.from_pretrained(self.hubert_model_path)
                self.model = HubertForCTC.from_pretrained(self.hubert_model_path)
                logger.info(f"âœ… ä»æœ¬åœ°è·¯å¾„åŠ è½½HuBERTæ¨¡å‹: {self.hubert_model_path}")
            else:
                # ä»HuggingFace HubåŠ è½½
                self.processor = Wav2Vec2Processor.from_pretrained(self.hubert_model_path)
                self.model = HubertForCTC.from_pretrained(self.hubert_model_path)
                logger.info(f"âœ… ä»HuggingFace HubåŠ è½½HuBERTæ¨¡å‹: {self.hubert_model_path}")
            
            # ç§»åŠ¨æ¨¡å‹åˆ°æŒ‡å®šè®¾å¤‡
            self.model.to(self.device)
            self.model.eval()
            
        except Exception as e:
            logger.error(f"âŒ HuBERTæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise

    def transcribe_audio(self, audio_path: str, sample_rate: int = 16000) -> str:
        """
        è½¬å½•å•ä¸ªéŸ³é¢‘æ–‡ä»¶

        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            sample_rate: é‡‡æ ·ç‡

        Returns:
            è½¬å½•æ–‡æœ¬
        """
        try:
            # åŠ è½½éŸ³é¢‘
            waveform, sr = torchaudio.load(audio_path)
            
            # é‡é‡‡æ ·åˆ°16kHzï¼ˆå¦‚æœéœ€è¦ï¼‰
            if sr != sample_rate:
                resampler = torchaudio.transforms.Resample(sr, sample_rate)
                waveform = resampler(waveform)
            
            # è½¬æ¢ä¸ºå•å£°é“
            if waveform.shape[0] > 1:
                waveform = torch.mean(waveform, dim=0, keepdim=True)
            
            # è½¬æ¢ä¸ºnumpyå¹¶å½’ä¸€åŒ–
            audio_array = waveform.squeeze().numpy()
            
            # ä½¿ç”¨å¤„ç†å™¨å¤„ç†éŸ³é¢‘
            inputs = self.processor(
                audio_array, 
                sampling_rate=sample_rate, 
                return_tensors="pt"
            )
            
            # ç§»åŠ¨åˆ°è®¾å¤‡
            input_values = inputs.input_values.to(self.device)
            
            # æ¨ç†
            with torch.no_grad():
                logits = self.model(input_values).logits
                predicted_ids = torch.argmax(logits, dim=-1)
                
            # è§£ç 
            transcription = self.processor.decode(predicted_ids[0])
            
            return transcription.strip()
            
        except Exception as e:
            logger.warning(f"è½¬å½•éŸ³é¢‘ {audio_path} å¤±è´¥: {e}")
            return ""

    def load_librispeech_transcripts(self, manifest_path: str) -> Dict[str, str]:
        """
        åŠ è½½LibriSpeechæµ‹è¯•é›†çš„å‚è€ƒè½¬å½•æ–‡æœ¬

        Args:
            manifest_path: manifestæ–‡ä»¶è·¯å¾„

        Returns:
            {utterance_id: text} å­—å…¸
        """
        transcripts = {}
        
        try:
            with open(manifest_path, 'r', encoding='utf-8') as f:
                for line in f:
                    data = json.loads(line.strip())
                    utterance_id = data['utterance_id']
                    text = data['text']
                    transcripts[utterance_id] = text
                    
            logger.info(f"âœ… åŠ è½½äº† {len(transcripts)} ä¸ªå‚è€ƒè½¬å½•æ–‡æœ¬")
            return transcripts
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½å‚è€ƒè½¬å½•æ–‡æœ¬å¤±è´¥: {e}")
            raise

    def find_metadata_files(self, eval_results_dir: str) -> List[str]:
        """
        æŸ¥æ‰¾æ‰€æœ‰å…ƒæ•°æ®æ–‡ä»¶

        Args:
            eval_results_dir: è¯„ä¼°ç»“æœç›®å½•

        Returns:
            å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        metadata_files = []
        eval_path = Path(eval_results_dir)
        
        # æŸ¥æ‰¾æ‰€æœ‰å…ƒæ•°æ®æ–‡ä»¶
        for metadata_file in eval_path.rglob("*_metadata.json"):
            metadata_files.append(str(metadata_file))
        
        logger.info(f"âœ… æ‰¾åˆ° {len(metadata_files)} ä¸ªéŸ³é¢‘å…ƒæ•°æ®æ–‡ä»¶")
        return sorted(metadata_files)

    def calculate_wer(self, eval_results_dir: str, manifest_path: str, 
                     output_dir: str = "wer_results", max_samples: Optional[int] = None) -> Dict:
        """
        è®¡ç®—WERåˆ†æ•°

        Args:
            eval_results_dir: è¯„ä¼°ç»“æœç›®å½•
            manifest_path: LibriSpeech manifestæ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            max_samples: æœ€å¤§å¤„ç†æ ·æœ¬æ•°

        Returns:
            WERè®¡ç®—ç»“æœ
        """
        logger.info("ğŸš€ å¼€å§‹WERè®¡ç®—...")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # åŠ è½½å‚è€ƒè½¬å½•æ–‡æœ¬
        reference_transcripts = self.load_librispeech_transcripts(manifest_path)
        
        # æŸ¥æ‰¾æ‰€æœ‰å…ƒæ•°æ®æ–‡ä»¶
        metadata_files = self.find_metadata_files(eval_results_dir)
        
        if max_samples:
            metadata_files = metadata_files[:max_samples]
            logger.info(f"ğŸ”¢ é™åˆ¶å¤„ç†æ ·æœ¬æ•°: {max_samples}")
        
        # å­˜å‚¨ç»“æœ
        results = []
        hypothesis_texts = []
        reference_texts = []
        successful_transcriptions = 0
        
        # åˆ›å»ºè¿›åº¦æ¡
        progress_bar = tqdm(
            metadata_files,
            desc="è½¬å½•éŸ³é¢‘",
            unit="æ–‡ä»¶",
            leave=True,
            dynamic_ncols=True
        )
        
        for metadata_file in progress_bar:
            try:
                # è¯»å–å…ƒæ•°æ®
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                
                sample_id = metadata['sample_id']
                original_filename = metadata['original_filename']
                dataset_name = metadata['dataset_name']
                
                # è·å–é‡å»ºéŸ³é¢‘è·¯å¾„
                metadata_dir = Path(metadata_file).parent
                reconstructed_audio_path = metadata_dir / metadata['saved_files']['reconstructed']
                
                if not reconstructed_audio_path.exists():
                    logger.warning(f"é‡å»ºéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {reconstructed_audio_path}")
                    continue
                
                # è·å–å‚è€ƒè½¬å½•æ–‡æœ¬
                if original_filename not in reference_transcripts:
                    logger.warning(f"æ‰¾ä¸åˆ°å‚è€ƒè½¬å½•æ–‡æœ¬: {original_filename}")
                    continue
                
                reference_text = reference_transcripts[original_filename]
                
                # è½¬å½•é‡å»ºéŸ³é¢‘
                hypothesis_text = self.transcribe_audio(str(reconstructed_audio_path))
                
                if not hypothesis_text:
                    logger.warning(f"è½¬å½•å¤±è´¥: {reconstructed_audio_path}")
                    continue
                
                # è®¡ç®—å•ä¸ªæ ·æœ¬çš„WER
                try:
                    sample_wer = jiwer.wer(reference_text, hypothesis_text)
                except:
                    sample_wer = 1.0  # å¦‚æœè®¡ç®—å¤±è´¥ï¼Œè®¾ä¸º100%é”™è¯¯ç‡
                
                # ä¿å­˜ç»“æœ
                result = {
                    'sample_id': sample_id,
                    'original_filename': original_filename,
                    'dataset_name': dataset_name,
                    'reference_text': reference_text,
                    'hypothesis_text': hypothesis_text,
                    'wer': sample_wer,
                    'pesq_wb': metadata.get('pesq_wb', 0.0),
                    'pesq_nb': metadata.get('pesq_nb', 0.0),
                    'stoi_score': metadata.get('stoi_score', 0.0)
                }
                results.append(result)
                
                # ç”¨äºæ€»ä½“WERè®¡ç®—
                hypothesis_texts.append(hypothesis_text)
                reference_texts.append(reference_text)
                
                successful_transcriptions += 1
                
                # æ›´æ–°è¿›åº¦æ¡
                if successful_transcriptions > 0:
                    current_wer = jiwer.wer(' '.join(reference_texts), ' '.join(hypothesis_texts))
                    progress_bar.set_postfix({
                        'WER': f'{current_wer:.3f}',
                        'æˆåŠŸ': f'{successful_transcriptions}'
                    })
                
            except Exception as e:
                logger.warning(f"å¤„ç†æ–‡ä»¶ {metadata_file} å¤±è´¥: {e}")
                continue
        
        progress_bar.close()
        
        if not results:
            logger.error("âŒ æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•éŸ³é¢‘æ–‡ä»¶")
            return {}
        
        # è®¡ç®—æ€»ä½“WER
        overall_wer = jiwer.wer(' '.join(reference_texts), ' '.join(hypothesis_texts))
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        individual_wers = [r['wer'] for r in results]
        avg_wer = np.mean(individual_wers)
        std_wer = np.std(individual_wers)
        min_wer = np.min(individual_wers)
        max_wer = np.max(individual_wers)
        
        # å‡†å¤‡æœ€ç»ˆç»“æœ
        final_results = {
            'overall_wer': overall_wer,
            'avg_individual_wer': avg_wer,
            'std_individual_wer': std_wer,
            'min_wer': min_wer,
            'max_wer': max_wer,
            'num_samples': len(results),
            'successful_transcriptions': successful_transcriptions,
            'total_metadata_files': len(metadata_files),
            'individual_results': results
        }
        
        # æ‰“å°ç»“æœ
        logger.info("\n" + "="*60)
        logger.info("ğŸ“Š WERè®¡ç®—ç»“æœ")
        logger.info("="*60)
        logger.info(f"ğŸ¯ æ€»ä½“WER: {overall_wer:.4f} ({overall_wer*100:.2f}%)")
        logger.info(f"ğŸ“ˆ å¹³å‡ä¸ªä½“WER: {avg_wer:.4f} (Â±{std_wer:.4f})")
        logger.info(f"ğŸ”º æœ€é«˜WER: {max_wer:.4f}")
        logger.info(f"ğŸ”» æœ€ä½WER: {min_wer:.4f}")
        logger.info(f"ğŸ“Š æˆåŠŸå¤„ç†æ ·æœ¬æ•°: {successful_transcriptions}/{len(metadata_files)}")
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        results_file = output_path / "wer_results.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(final_results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
        
        # ä¿å­˜è½¬å½•æ–‡æœ¬å¯¹æ¯”
        transcription_file = output_path / "transcriptions.jsonl"
        with open(transcription_file, 'w', encoding='utf-8') as f:
            for result in results:
                f.write(json.dumps(result, ensure_ascii=False) + '\n')
        
        logger.info(f"ğŸ“„ è½¬å½•æ–‡æœ¬å¯¹æ¯”å·²ä¿å­˜åˆ°: {transcription_file}")
        
        return final_results


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="WERè®¡ç®—è„šæœ¬")
    parser.add_argument(
        "--eval-results-dir",
        type=str,
        required=True,
        help="è¯„ä¼°ç»“æœç›®å½•ï¼ˆåŒ…å«éŸ³é¢‘å’Œå…ƒæ•°æ®æ–‡ä»¶ï¼‰"
    )
    parser.add_argument(
        "--manifest-path",
        type=str,
        default="/root/autodl-tmp/WhisperCodec/data/manifests/librispeech/librispeech_test_clean.jsonl",
        help="LibriSpeech test-clean manifestæ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--hubert-model-path",
        type=str,
        default="/root/autodl-tmp/hubert_large_model",
        help="HuBERTæ¨¡å‹è·¯å¾„ï¼ˆæœ¬åœ°è·¯å¾„æˆ–HuggingFaceæ¨¡å‹åï¼‰"
    )
    parser.add_argument(
        "--device",
        type=str,
        default="auto",
        help="è®¡ç®—è®¾å¤‡ (auto, cpu, cuda, cuda:0ç­‰)"
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default="wer_results",
        help="ç»“æœè¾“å‡ºç›®å½•"
    )
    parser.add_argument(
        "--max-samples",
        type=int,
        default=None,
        help="æœ€å¤§å¤„ç†æ ·æœ¬æ•°ï¼ŒNoneè¡¨ç¤ºå…¨éƒ¨"
    )

    args = parser.parse_args()

    try:
        # åˆ›å»ºWERè®¡ç®—å™¨
        calculator = WERCalculator(
            hubert_model_path=args.hubert_model_path,
            device=args.device
        )

        # è®¡ç®—WER
        results = calculator.calculate_wer(
            eval_results_dir=args.eval_results_dir,
            manifest_path=args.manifest_path,
            output_dir=args.output_dir,
            max_samples=args.max_samples
        )

        if results:
            logger.info("âœ… WERè®¡ç®—å®Œæˆï¼")
            logger.info(f"ğŸ¯ æ€»ä½“WER: {results['overall_wer']:.4f}")
        else:
            logger.error("âŒ WERè®¡ç®—å¤±è´¥ï¼")

    except Exception as e:
        logger.error(f"âŒ WERè®¡ç®—è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
