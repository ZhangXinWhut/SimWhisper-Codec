#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AudioCodec æ¨¡å‹è¯„ä¼°è„šæœ¬

åŠŸèƒ½ï¼š
- åŠ è½½æŒ‡å®šæ¨¡å‹æƒé‡è¿›è¡Œæ¨ç†
- è®¡ç®—å¹³å‡PESQåˆ†æ•°
- è®°å½•æœ€é«˜ä¸‰ä¸ªPESQåˆ†æ•°çš„éŸ³é¢‘æ–‡ä»¶å/è·¯å¾„
- é»˜è®¤ä½¿ç”¨latestæ¨¡å‹è¯„ä¼°
- ä½¿ç”¨YAMLé…ç½®æ–‡ä»¶ä¸­çš„æµ‹è¯•æ•°æ®é›†
"""

import os
import sys
import json
import yaml
import torch
import logging
import argparse
import numpy as np
from pathlib import Path
from tqdm import tqdm
from typing import Dict, List, Tuple, Optional
from collections import namedtuple
import torchaudio

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°æ¨¡å—è·¯å¾„
current_file = os.path.abspath(__file__)
project_root = current_file
for _ in range(2):
    project_root = os.path.dirname(project_root)
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from audiocodec.model import AudioCodec
from audiocodec.trainer.dataset import get_audio_dataloader
from audiocodec.trainer.evaluator import calculate_pesq_wb_nb, calculate_stoi
from audiocodec.trainer.trainer import AudioCodecTrainer

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('evaluation.log', mode='w')
    ]
)
logger = logging.getLogger(__name__)

# å®šä¹‰è¯„ä¼°ç»“æœç»“æ„
EvaluationResult = namedtuple('EvaluationResult', [
    'pesq_wb', 'pesq_nb', 'stoi_score',  # å„é¡¹æŒ‡æ ‡åˆ†æ•°
    'audio_filepath', 'dataset_name',    # æ–‡ä»¶ä¿¡æ¯
    'reconstructed_audio', 'original_audio'  # éŸ³é¢‘æ•°æ®
])

class ModelEvaluator:
    """æ¨¡å‹è¯„ä¼°å™¨"""

    def __init__(self, config_path: str, model_tag: str = "latest", device: str = "auto", training_stage: str = None, save_all_audio: bool = False):
        """
        åˆå§‹åŒ–è¯„ä¼°å™¨

        Args:
            config_path: YAMLé…ç½®æ–‡ä»¶è·¯å¾„
            model_tag: æ¨¡å‹æ ‡ç­¾ (latest, best_model, æˆ–å…·ä½“epochæ ‡ç­¾)
            device: è®¾å¤‡ ('auto', 'cpu', 'cuda', 'cuda:0'ç­‰)
            training_stage: è®­ç»ƒé˜¶æ®µ ('pretrain', 'posttrain', æˆ– Noneè‡ªåŠ¨æ£€æµ‹)
            save_all_audio: æ˜¯å¦ä¿å­˜æ‰€æœ‰ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶
        """
        self.config_path = config_path
        self.model_tag = model_tag
        self.device = self._setup_device(device)
        self.save_all_audio = save_all_audio

        # åŠ è½½é…ç½®
        self.config = self._load_config()

        # è‡ªåŠ¨æ£€æµ‹è®­ç»ƒé˜¶æ®µ
        self.training_stage = training_stage or self._detect_training_stage()

        # åˆå§‹åŒ–æ¨¡å‹
        self.model = self._initialize_model()

        # åŠ è½½æ¨¡å‹æƒé‡
        self._load_model_weights()

        # åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨
        self.test_loader = self._create_test_loader()

        logger.info("âœ… æ¨¡å‹è¯„ä¼°å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"  ğŸ“‹ é…ç½®æ–‡ä»¶: {config_path}")
        logger.info(f"  ğŸ·ï¸  æ¨¡å‹æ ‡ç­¾: {model_tag}")
        logger.info(f"  ğŸ¯ è®­ç»ƒé˜¶æ®µ: {self.training_stage}")
        logger.info(f"  ğŸ’» è®¾å¤‡: {self.device}")
        logger.info(f"  ğŸ“Š æµ‹è¯•æ•°æ®é›†å¤§å°: {len(self.test_loader.dataset)}")

    def _detect_training_stage(self) -> str:
        """è‡ªåŠ¨æ£€æµ‹è®­ç»ƒé˜¶æ®µ"""
        # æ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­æ˜¯å¦æœ‰pretrained_checkpoint
        training_config = self.config.get('training', {})

        # å¦‚æœæœ‰pretrained_checkpointï¼Œåˆ™æ˜¯åè®­ç»ƒé˜¶æ®µ
        if 'pretrained_checkpoint' in training_config:
            logger.info("ğŸ” æ£€æµ‹åˆ°é¢„è®­ç»ƒæ£€æŸ¥ç‚¹é…ç½®ï¼Œåˆ¤æ–­ä¸ºåè®­ç»ƒæ¨¡å‹")
            return 'posttrain'
        else:
            logger.info("ğŸ” æœªæ£€æµ‹åˆ°é¢„è®­ç»ƒæ£€æŸ¥ç‚¹é…ç½®ï¼Œåˆ¤æ–­ä¸ºé¢„è®­ç»ƒæ¨¡å‹")
            return 'pretrain'

    def _setup_device(self, device: str) -> torch.device:
        """è®¾ç½®è®¡ç®—è®¾å¤‡"""
        if device == "auto":
            if torch.cuda.is_available():
                return torch.device('cuda:0')
            else:
                return torch.device('cpu')
        else:
            return torch.device(device)

    def _load_config(self) -> Dict:
        """åŠ è½½YAMLé…ç½®æ–‡ä»¶"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            logger.info(f"âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {self.config_path}")
            return config
        except Exception as e:
            logger.error(f"âŒ é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
            raise

    def _initialize_model(self) -> AudioCodec:
        """åˆå§‹åŒ–æ¨¡å‹"""
        try:
            model_config = self.config.get('model', {})

            # AudioCodec æ„é€ å‡½æ•°éœ€è¦ generator_params å‚æ•°
            model = AudioCodec(
                generator_params=model_config,
                initialize_whisper=False  # è¯„ä¼°æ—¶ä¸éœ€è¦åˆå§‹åŒ– Whisper æƒé‡ï¼Œä¼šä»æ£€æŸ¥ç‚¹åŠ è½½
            )

            model.to(self.device)
            model.eval()

            logger.info("âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
            return model

        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def _load_model_weights(self):
        """åŠ è½½æ¨¡å‹æƒé‡"""
        try:
            # ç¡®å®šæ£€æŸ¥ç‚¹æ ¹ç›®å½• - åŸºäºé…ç½®æ–‡ä»¶å’Œè®­ç»ƒé˜¶æ®µ
            config_checkpoint_dir = self.config.get('checkpoint_dir')

            if config_checkpoint_dir:
                # å¦‚æœé…ç½®æ–‡ä»¶ä¸­æœ‰checkpoint_dirï¼Œä½¿ç”¨å®ƒ
                checkpoint_root = config_checkpoint_dir
                logger.info(f"ğŸ“‚ ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ£€æŸ¥ç‚¹ç›®å½•: {checkpoint_root}")
            else:
                # å¦‚æœæ²¡æœ‰ï¼Œæ ¹æ®è®­ç»ƒé˜¶æ®µè‡ªåŠ¨ç¡®å®š
                if self.training_stage == 'posttrain':
                    checkpoint_root = 'outputs/posttrain/checkpoints'
                    logger.info(f"ğŸ“‚ åè®­ç»ƒé˜¶æ®µï¼Œä½¿ç”¨é»˜è®¤æ£€æŸ¥ç‚¹ç›®å½•: {checkpoint_root}")
                else:
                    checkpoint_root = 'outputs/pretrain/checkpoints'
                    logger.info(f"ğŸ“‚ é¢„è®­ç»ƒé˜¶æ®µï¼Œä½¿ç”¨é»˜è®¤æ£€æŸ¥ç‚¹ç›®å½•: {checkpoint_root}")

            # åŠ è½½æ¨¡å‹æƒé‡
            success = AudioCodecTrainer.load_model_weights(
                self.model,
                checkpoint_root,
                tag=self.model_tag
            )

            if success:
                logger.info(f"âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ: {checkpoint_root} (tag: {self.model_tag})")
            else:
                logger.warning(f"âš ï¸ æ¨¡å‹æƒé‡åŠ è½½å¯èƒ½ä¸å®Œæ•´: {checkpoint_root} (tag: {self.model_tag})")

        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹æƒé‡åŠ è½½å¤±è´¥: {e}")
            raise

    def _create_test_loader(self):
        """åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨"""
        try:
            test_loader = get_audio_dataloader(
                self.config,
                stage='test',
                world_size=1,
                rank=0
            )
            logger.info("âœ… æµ‹è¯•æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
            return test_loader
        except Exception as e:
            logger.error(f"âŒ æµ‹è¯•æ•°æ®åŠ è½½å™¨åˆ›å»ºå¤±è´¥: {e}")
            raise

    def evaluate_model(self, max_samples: Optional[int] = None, output_dir: str = "evaluation_results") -> Dict:
        """
        è¯„ä¼°æ¨¡å‹æ€§èƒ½

        Args:
            max_samples: æœ€å¤§è¯„ä¼°æ ·æœ¬æ•°ï¼ŒNoneè¡¨ç¤ºå…¨éƒ¨
            output_dir: è¾“å‡ºç›®å½•è·¯å¾„

        Returns:
            è¯„ä¼°ç»“æœå­—å…¸
        """
        logger.info("ğŸš€ å¼€å§‹æ¨¡å‹è¯„ä¼°...")
        
        # å¦‚æœéœ€è¦ä¿å­˜æ‰€æœ‰éŸ³é¢‘ï¼Œåˆ›å»ºè¾“å‡ºç›®å½•
        all_audio_save_dir = None
        if self.save_all_audio:
            all_audio_save_dir = Path(output_dir) / "all_audio_samples"
            all_audio_save_dir.mkdir(parents=True, exist_ok=True)
            logger.info(f"ğŸµ å°†ä¿å­˜æ‰€æœ‰ç”Ÿæˆçš„éŸ³é¢‘åˆ°: {all_audio_save_dir}")

        pesq_scores = []
        pesq_results = []  # ä¿å­˜æ‰€æœ‰PESQç»“æœç”¨äºæ’åº

        # è®¡ç®—æ€»æ ·æœ¬æ•°ç”¨äºè¿›åº¦æ¡
        if max_samples:
            total_samples = max_samples
        else:
            # è®¡ç®—æ•°æ®é›†çš„æ€»æ ·æœ¬æ•°
            total_samples = len(self.test_loader.dataset)

        progress_bar = tqdm(
            total=total_samples,
            desc="è¯„ä¼°è¿›åº¦",
            unit="æ ·æœ¬",
            leave=True,
            dynamic_ncols=True,
            bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}{postfix}]'
        )

        sample_count = 0

        # å­˜å‚¨å„é¡¹æŒ‡æ ‡çš„åˆ—è¡¨
        pesq_wb_scores = []
        pesq_nb_scores = []
        stoi_scores = []
        eval_results = []  # å­˜å‚¨è¯„ä¼°ç»“æœç”¨äºåç»­æ’åº

        with torch.no_grad():
            for batch_idx, batch in enumerate(self.test_loader):
                if max_samples and sample_count >= max_samples:
                    break

                try:
                    # å‡†å¤‡æ•°æ®
                    audio_list = batch['audio_list']
                    audio_lengths = batch['audio_lens'].to(self.device)
                    audio_filepaths = batch['audio_filepaths']
                    dataset_names = batch['dataset_names']

                    # æ¨¡å‹æ¨ç† - ä½¿ç”¨æ£€æµ‹åˆ°çš„è®­ç»ƒé˜¶æ®µ
                    outputs = self.model(
                        audio_list=audio_list,
                        audio_lengths=audio_lengths,
                        training_stage=self.training_stage
                    )

                    # è·å–é‡å»ºéŸ³é¢‘
                    if 'reconstructed_audio' not in outputs:
                        logger.warning(f"æ‰¹æ¬¡ {batch_idx}: æœªæ‰¾åˆ°é‡å»ºéŸ³é¢‘ï¼Œè·³è¿‡")
                        continue

                    reconstructed_audio = outputs['reconstructed_audio']

                    # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„PESQåˆ†æ•°
                    for i in range(len(audio_list)):
                        original_audio = audio_list[i]
                        reconstructed = reconstructed_audio[i, 0]  # å‡è®¾æ˜¯ (batch, 1, seq_len) æ ¼å¼

                        # ç¡®ä¿é•¿åº¦åŒ¹é…
                        min_length = min(len(original_audio), len(reconstructed))
                        original_audio = original_audio[:min_length]
                        reconstructed = reconstructed[:min_length]

                        # è®¡ç®—å„é¡¹æŒ‡æ ‡
                        try:
                            # è®¡ç®—PESQ-WBå’ŒPESQ-NB
                            pesq_wb, pesq_nb = calculate_pesq_wb_nb(
                                original_audio=original_audio,
                                reconstructed_audio=reconstructed,
                                sample_rate=self.config.get('sample_rate', 16000)
                            )

                            # è®¡ç®—STOI
                            stoi_score = calculate_stoi(
                                original_audio=original_audio,
                                reconstructed_audio=reconstructed,
                                sample_rate=self.config.get('sample_rate', 16000)
                            )

                            # æ·»åŠ åˆ°å„ä¸ªæŒ‡æ ‡åˆ—è¡¨
                            pesq_wb_scores.append(pesq_wb)
                            pesq_nb_scores.append(pesq_nb)
                            stoi_scores.append(stoi_score)

                            # ä¿å­˜è¯„ä¼°ç»“æœç”¨äºåç»­æ’åºï¼ˆåŒ…å«éŸ³é¢‘æ•°æ®ï¼‰
                            result = EvaluationResult(
                                pesq_wb=pesq_wb,
                                pesq_nb=pesq_nb,
                                stoi_score=stoi_score,
                                audio_filepath=audio_filepaths[i],
                                dataset_name=dataset_names[i],
                                reconstructed_audio=reconstructed.detach().cpu(),  # ä¿å­˜é‡å»ºéŸ³é¢‘
                                original_audio=original_audio.detach().cpu()       # ä¿å­˜åŸå§‹éŸ³é¢‘
                            )
                            eval_results.append(result)

                            # å¦‚æœå¯ç”¨äº†ä¿å­˜æ‰€æœ‰éŸ³é¢‘åŠŸèƒ½ï¼Œä¿å­˜å½“å‰éŸ³é¢‘
                            if self.save_all_audio and all_audio_save_dir is not None:
                                self._save_single_audio_sample(result, sample_count, all_audio_save_dir)

                            sample_count += 1

                            # æ¯å¤„ç†ä¸€ä¸ªæ ·æœ¬å°±æ›´æ–°è¿›åº¦æ¡
                            progress_bar.update(1)
                            if pesq_wb_scores:
                                avg_pesq_wb = np.mean(pesq_wb_scores)
                                avg_pesq_nb = np.mean(pesq_nb_scores)
                                avg_stoi = np.mean(stoi_scores)
                                postfix_dict = {
                                    'PESQ-WB': f'{avg_pesq_wb:.3f}',
                                    'PESQ-NB': f'{avg_pesq_nb:.3f}',
                                    'STOI': f'{avg_stoi:.3f}',
                                    'æ ·æœ¬æ•°': f'{sample_count}'
                                }
                                if self.save_all_audio:
                                    postfix_dict['éŸ³é¢‘å·²ä¿å­˜'] = 'âœ“'
                                progress_bar.set_postfix(postfix_dict)

                        except Exception as e:
                            logger.warning(f"æ ·æœ¬ {i} PESQè®¡ç®—å¤±è´¥: {e}")
                            # å³ä½¿PESQè®¡ç®—å¤±è´¥ï¼Œä¹Ÿè¦æ›´æ–°è¿›åº¦æ¡ä»¥åæ˜ å¤„ç†è¿›åº¦
                            progress_bar.update(1)
                            continue

                except Exception as e:
                    logger.warning(f"æ‰¹æ¬¡ {batch_idx} å¤„ç†å¤±è´¥: {e}")
                    # æ‰¹æ¬¡å¤±è´¥æ—¶ï¼Œéœ€è¦æ›´æ–°å¯¹åº”æ•°é‡çš„è¿›åº¦æ¡
                    progress_bar.update(len(audio_list))
                    continue

        progress_bar.close()

        # è®¡ç®—æœ€ç»ˆç»Ÿè®¡ç»“æœ
        if not pesq_wb_scores:
            logger.error("âŒ æ²¡æœ‰æˆåŠŸè®¡ç®—ä»»ä½•è¯„ä¼°æŒ‡æ ‡")
            return {}

        # è®¡ç®—å„é¡¹æŒ‡æ ‡çš„ç»Ÿè®¡ä¿¡æ¯
        avg_pesq_wb = np.mean(pesq_wb_scores)
        std_pesq_wb = np.std(pesq_wb_scores)
        min_pesq_wb = np.min(pesq_wb_scores)
        max_pesq_wb = np.max(pesq_wb_scores)

        avg_pesq_nb = np.mean(pesq_nb_scores)
        std_pesq_nb = np.std(pesq_nb_scores)

        avg_stoi = np.mean(stoi_scores)
        std_stoi = np.std(stoi_scores)

        # è·å–å‰5ä¸ªæœ€é«˜PESQ-WBåˆ†æ•°çš„æ ·æœ¬
        top_5_results = sorted(eval_results, key=lambda x: x.pesq_wb, reverse=True)[:5]

        # æ‰“å°è¯„ä¼°ç»“æœ
        logger.info("\n" + "="*60)
        logger.info("ğŸ“Š æ¨¡å‹è¯„ä¼°ç»“æœ")
        logger.info("="*60)
        logger.info(f"ğŸ¯ å¹³å‡PESQ-WB: {avg_pesq_wb:.4f} (Â±{std_pesq_wb:.4f})")
        logger.info(f"ğŸ¯ å¹³å‡PESQ-NB: {avg_pesq_nb:.4f} (Â±{std_pesq_nb:.4f})")
        logger.info(f"ğŸ¯ å¹³å‡STOI: {avg_stoi:.4f} (Â±{std_stoi:.4f})")
        logger.info(f"ğŸ“Š è¯„ä¼°æ ·æœ¬æ•°: {len(pesq_wb_scores)}")
        logger.info(f"ğŸ”º æœ€é«˜PESQ-WB: {max_pesq_wb:.4f}")
        logger.info(f"ğŸ”» æœ€ä½PESQ-WB: {min_pesq_wb:.4f}")

        logger.info("\nğŸ† å‰5ä¸ªæœ€é«˜PESQ-WBåˆ†æ•°çš„éŸ³é¢‘æ–‡ä»¶:")
        for i, result in enumerate(top_5_results, 1):
            logger.info(f"  {i}. PESQ-WB: {result.pesq_wb:.4f}, PESQ-NB: {result.pesq_nb:.4f}, STOI: {result.stoi_score:.4f}")
            logger.info(f"     æ–‡ä»¶: {result.audio_filepath}")
            logger.info(f"     æ•°æ®é›†: {result.dataset_name}")

        # ä¿å­˜å‰5ä¸ªæœ€é«˜PESQ-WBåˆ†æ•°çš„éŸ³é¢‘æ–‡ä»¶
        self._save_top5_audio_files(top_5_results)
        
        # å¦‚æœå¯ç”¨äº†ä¿å­˜æ‰€æœ‰éŸ³é¢‘åŠŸèƒ½ï¼Œè®°å½•ä¿å­˜çš„éŸ³é¢‘æ–‡ä»¶æ•°é‡
        if self.save_all_audio and all_audio_save_dir is not None:
            logger.info(f"\nğŸ“ æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶å·²ä¿å­˜åˆ°: {all_audio_save_dir}")
            logger.info(f"ğŸµ å…±ä¿å­˜äº† {len(pesq_wb_scores)} ä¸ªéŸ³é¢‘æ ·æœ¬ï¼ˆæ¯ä¸ªæ ·æœ¬åŒ…å«åŸå§‹éŸ³é¢‘å’Œé‡å»ºéŸ³é¢‘ï¼‰")

        # ä¿å­˜è¯¦ç»†ç»“æœåˆ°æ–‡ä»¶
        self._save_evaluation_results(eval_results, avg_pesq_wb, std_pesq_wb, avg_pesq_nb, std_pesq_nb, avg_stoi, std_stoi)

        return {
            'avg_pesq_wb': avg_pesq_wb,
            'std_pesq_wb': std_pesq_wb,
            'avg_pesq_nb': avg_pesq_nb,
            'std_pesq_nb': std_pesq_nb,
            'avg_stoi': avg_stoi,
            'std_stoi': std_stoi,
            'min_pesq_wb': min_pesq_wb,
            'max_pesq_wb': max_pesq_wb,
            'num_samples': len(pesq_wb_scores),
            'top_5_results': top_5_results,
            'all_pesq_wb_scores': pesq_wb_scores,
            'all_pesq_nb_scores': pesq_nb_scores,
            'all_stoi_scores': stoi_scores
        }

    def _save_single_audio_sample(self, result: EvaluationResult, sample_count: int, save_dir: Path):
        """ä¿å­˜å•ä¸ªéŸ³é¢‘æ ·æœ¬ï¼ˆåŸå§‹éŸ³é¢‘å’Œé‡å»ºéŸ³é¢‘ï¼‰"""
        try:
            sample_rate = self.config.get('sample_rate', 16000)
            
            # ä»æ–‡ä»¶è·¯å¾„ä¸­æå–æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
            original_filename = Path(result.audio_filepath).stem
            dataset_name = result.dataset_name
            
            # åˆ›å»ºæ•°æ®é›†å­ç›®å½•
            dataset_dir = save_dir / dataset_name
            dataset_dir.mkdir(exist_ok=True)
            
            # åˆ›å»ºä¿å­˜çš„æ–‡ä»¶åï¼ˆä½¿ç”¨æ ·æœ¬è®¡æ•°ç¡®ä¿å”¯ä¸€æ€§ï¼‰
            original_file = dataset_dir / f"sample_{sample_count:06d}_{original_filename}_original.wav"
            reconstructed_file = dataset_dir / f"sample_{sample_count:06d}_{original_filename}_reconstructed.wav"
            
            # ä¿å­˜åŸå§‹éŸ³é¢‘
            torchaudio.save(str(original_file), result.original_audio.unsqueeze(0), sample_rate)
            
            # ä¿å­˜é‡å»ºéŸ³é¢‘
            torchaudio.save(str(reconstructed_file), result.reconstructed_audio.unsqueeze(0), sample_rate)
            
            # åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶è®°å½•è¯„ä¼°æŒ‡æ ‡
            metadata_file = dataset_dir / f"sample_{sample_count:06d}_{original_filename}_metadata.json"
            metadata = {
                "sample_id": sample_count,
                "original_filename": original_filename,
                "dataset_name": dataset_name,
                "audio_filepath": result.audio_filepath,
                "pesq_wb": float(result.pesq_wb),
                "pesq_nb": float(result.pesq_nb),
                "stoi_score": float(result.stoi_score),
                "saved_files": {
                    "original": str(original_file.name),
                    "reconstructed": str(reconstructed_file.name)
                }
            }
            
            import json
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            logger.warning(f"ä¿å­˜éŸ³é¢‘æ ·æœ¬ {sample_count} å¤±è´¥: {e}")

    def _save_top5_audio_files(self, top_5_results: List[EvaluationResult]):
        """ä¿å­˜å‰5ä¸ªæœ€é«˜PESQ-WBåˆ†æ•°çš„éŸ³é¢‘æ–‡ä»¶"""
        try:
            # åˆ›å»ºéŸ³é¢‘ä¿å­˜ç›®å½•
            audio_save_dir = Path("evaluation_results/audio_samples")
            audio_save_dir.mkdir(parents=True, exist_ok=True)

            sample_rate = self.config.get('sample_rate', 16000)

            logger.info(f"\nğŸµ ä¿å­˜å‰5ä¸ªæœ€é«˜PESQ-WBåˆ†æ•°çš„éŸ³é¢‘æ–‡ä»¶åˆ°: {audio_save_dir}")

            for i, result in enumerate(top_5_results, 1):
                # ä»æ–‡ä»¶è·¯å¾„ä¸­æå–æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
                original_filename = Path(result.audio_filepath).stem
                dataset_name = result.dataset_name

                # åˆ›å»ºä¿å­˜çš„æ–‡ä»¶å
                original_file = audio_save_dir / f"top{i:02d}_{original_filename}_original.wav"
                reconstructed_file = audio_save_dir / f"top{i:02d}_{original_filename}_reconstructed.wav"

                # ä¿å­˜åŸå§‹éŸ³é¢‘
                torchaudio.save(original_file, result.original_audio.unsqueeze(0), sample_rate)

                # ä¿å­˜é‡å»ºéŸ³é¢‘
                torchaudio.save(reconstructed_file, result.reconstructed_audio.unsqueeze(0), sample_rate)

                logger.info(f"  âœ… å·²ä¿å­˜ç¬¬{i}åéŸ³é¢‘æ–‡ä»¶:")
                logger.info(f"     åŸå§‹éŸ³é¢‘: {original_file}")
                logger.info(f"     é‡å»ºéŸ³é¢‘: {reconstructed_file}")
                logger.info(f"     PESQ-WB: {result.pesq_wb:.4f}, PESQ-NB: {result.pesq_nb:.4f}, STOI: {result.stoi_score:.4f}")
                logger.info(f"     æ•°æ®é›†: {dataset_name}")

        except Exception as e:
            logger.warning(f"ä¿å­˜éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {e}")
            import traceback
            logger.warning(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")

    def _save_evaluation_results(self, eval_results: List[EvaluationResult],
                                avg_pesq_wb: float, std_pesq_wb: float,
                                avg_pesq_nb: float, std_pesq_nb: float,
                                avg_stoi: float, std_stoi: float):
        """ä¿å­˜è¯„ä¼°ç»“æœåˆ°æ–‡ä»¶"""
        try:
            results_dir = Path("evaluation_results")
            results_dir.mkdir(exist_ok=True)

            # ä¿å­˜è¯¦ç»†ç»“æœ
            results_file = results_dir / f"evaluation_{self.model_tag}_{Path(self.config_path).stem}.json"

            # æå–å„é¡¹æŒ‡æ ‡çš„åˆ†æ•°åˆ—è¡¨
            pesq_wb_scores = [result.pesq_wb for result in eval_results]
            pesq_nb_scores = [result.pesq_nb for result in eval_results]
            stoi_scores = [result.stoi_score for result in eval_results]

            # è·å–å‰5ä¸ªæœ€é«˜PESQ-WBçš„ç»“æœ
            top_5_results = sorted(eval_results, key=lambda x: x.pesq_wb, reverse=True)[:5]

            results_data = {
                'model_tag': self.model_tag,
                'config_file': str(self.config_path),
                'evaluation_time': str(torch.tensor(0.).new_zeros(1).to(self.device).device),  # è·å–å½“å‰æ—¶é—´
                'statistics': {
                    'avg_pesq_wb': float(avg_pesq_wb),
                    'std_pesq_wb': float(std_pesq_wb),
                    'avg_pesq_nb': float(avg_pesq_nb),
                    'std_pesq_nb': float(std_pesq_nb),
                    'avg_stoi': float(avg_stoi),
                    'std_stoi': float(std_stoi),
                    'min_pesq_wb': float(np.min(pesq_wb_scores)),
                    'max_pesq_wb': float(np.max(pesq_wb_scores)),
                    'num_samples': len(pesq_wb_scores)
                },
                'top_5_results': [
                    {
                        'rank': i+1,
                        'pesq_wb': float(result.pesq_wb),
                        'pesq_nb': float(result.pesq_nb),
                        'stoi_score': float(result.stoi_score),
                        'audio_filepath': result.audio_filepath,
                        'dataset_name': result.dataset_name
                    }
                    for i, result in enumerate(top_5_results)
                ],
                'all_scores': [
                    {
                        'pesq_wb': float(result.pesq_wb),
                        'pesq_nb': float(result.pesq_nb),
                        'stoi_score': float(result.stoi_score),
                        'audio_filepath': result.audio_filepath,
                        'dataset_name': result.dataset_name
                    }
                    for result in eval_results
                ]
            }

            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(results_data, f, indent=2, ensure_ascii=False)

            logger.info(f"ğŸ’¾ è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°: {results_file}")

        except Exception as e:
            logger.warning(f"ä¿å­˜è¯„ä¼°ç»“æœå¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="AudioCodec æ¨¡å‹è¯„ä¼°è„šæœ¬")
    parser.add_argument(
        "--config",
        type=str,
        default="config/pretrain_config.yaml",
        help="YAMLé…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config/pretrain_config.yaml)"
    )
    parser.add_argument(
        "--model-tag",
        type=str,
        default="latest",
        help="æ¨¡å‹æ ‡ç­¾ (latest, best_model, æˆ–å…·ä½“epochæ ‡ç­¾ï¼Œé»˜è®¤: latest)"
    )
    parser.add_argument(
        "--device",
        type=str,
        default="auto",
        help="è®¡ç®—è®¾å¤‡ (auto, cpu, cuda, cuda:0ç­‰ï¼Œé»˜è®¤: auto)"
    )
    parser.add_argument(
        "--max-samples",
        type=int,
        default=None,
        help="æœ€å¤§è¯„ä¼°æ ·æœ¬æ•°ï¼ŒNoneè¡¨ç¤ºå…¨éƒ¨ (é»˜è®¤: None)"
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default="evaluation_results",
        help="ç»“æœè¾“å‡ºç›®å½• (é»˜è®¤: evaluation_results)"
    )
    parser.add_argument(
        "--training-stage",
        type=str,
        default=None,
        choices=['pretrain', 'posttrain'],
        help="è®­ç»ƒé˜¶æ®µ (pretrain/posttrainï¼Œé»˜è®¤è‡ªåŠ¨æ£€æµ‹)"
    )
    parser.add_argument(
        "--save-all-audio",
        action="store_true",
        help="ä¿å­˜æ‰€æœ‰ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶ï¼ˆåŸå§‹éŸ³é¢‘å’Œé‡å»ºéŸ³é¢‘ï¼‰"
    )

    args = parser.parse_args()

    try:
        # åˆ›å»ºè¯„ä¼°å™¨
        evaluator = ModelEvaluator(
            config_path=args.config,
            model_tag=args.model_tag,
            device=args.device,
            training_stage=args.training_stage,
            save_all_audio=args.save_all_audio
        )

        # æ‰§è¡Œè¯„ä¼°
        results = evaluator.evaluate_model(max_samples=args.max_samples, output_dir=args.output_dir)

        if results:
            logger.info("âœ… æ¨¡å‹è¯„ä¼°å®Œæˆï¼")
        else:
            logger.error("âŒ æ¨¡å‹è¯„ä¼°å¤±è´¥ï¼")

    except Exception as e:
        logger.error(f"âŒ è¯„ä¼°è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
